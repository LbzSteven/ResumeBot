# ğŸ“„ ResumeBot

**ResumeBot** is a locally-deployed resume and cover letter generation chatbot, powered by a local LLM engine and a simple web interface. It helps users quickly generate tailored job application materials based on their skills and job descriptions.

ğŸš€ This is the **MVP version** â€” stateless, one-time conversations without persistent storage.

## ğŸ”§ Tech Stack

- **Frontend**: [Streamlit](https://streamlit.io/) â€“ for building the interactive UI
- **Backend**: [FastAPI](https://fastapi.tiangolo.com/) â€“ for handling prompt logic and model interaction
- **LLM Engine**: [Ollama](https://ollama.com/) â€“ runs models like `llama2`, `mistral`, or `gemma` locally

> ğŸ§­ Planned features:
> - Retrieval-Augmented Generation (RAG) with FAISS
> - Session memory and multi-turn conversations
> - Skill extraction and job matching

## ğŸ› ï¸ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/resume-bot.git
cd resume-bot
```
### 2. Install Dependencies
```
conda env create -f environment.yml
```
### 3. Start the LLM Model (via Ollama)
    ollama run llama2

### 4. Launch the Backend (FastAPI)
```
uvicorn main:app --reload
```

### 5. Start the Frontend (Streamlit)
```
streamlit run frontend/app.py
```
Open your browser and go to: http://localhost:8501

## Project Structure

```
resume-bot/
â”‚
â”œâ”€â”€ backend/                  # FastAPI backend
â”‚        â”œâ”€â”€ prompts/              # Prompt templates and formatting logic
â”‚           â””â”€â”€ dialog_template.txt
â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ chat.py               # chat session function
â”‚   â””â”€â”€ generate.py           # generate prompt and make
â”œâ”€â”€ web/                  # Streamlit frontend
â”‚        â”œâ”€â”€ utils/              # Prompt templates and formatting logic
â”‚        â”‚      â””â”€â”€ constant.py # constant settings
â”‚        â”‚      â””â”€â”€ json_util.py # utils to manage read and write defuault input
â”‚        â”‚      â””â”€â”€ output_util.py # utils to manage save output
â”‚        â”œâ”€â”€ defaults/  # save your default input
â”‚        â”œâ”€â”€ output/  # save your output
â”‚        â””â”€â”€ app.py
â”‚
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md

```


## ğŸš§ Roadmap
 Multi-turn conversation and chat memory

 Job description parsing and skill alignment

 RAG integration with FAISS + LangChain

 User management and history (via database)

## ğŸ“„ License
MIT License.

This project is under active development. Contributions and feedback are welcome!
